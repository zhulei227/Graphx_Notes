{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个图中的三角形个数(不区分边的方向)，可以在一定程度上反映该图的联通性，我们可以先通过两次简单的aggerateMessages得到每个节点的三角形统计值，流程如下：   \n",
    "![avatar](./pic/三角形计数.png)\n",
    "\n",
    "图1表示初始图，每个节点的标识符表示为a,b,c,   \n",
    "\n",
    "1）第一次aggerateMessages：首先各节点将其标识符发送给它的邻居节点，每个节点收到邻居收到邻居节点发送来的消息，将其与自己的标识符拼接为一个列表，如a节点，拼接后为[[a,b],[a,c]],得到图2,   \n",
    "2）第二次aggerateMessages：然后继续，将当前的list发送给邻居，比如a节点将[[a,b],[a,c]]发送给邻居节点b，b接受到a发来的list之后，将自己的列表[[b,a],[b,c]]与其合并，合并方式为：依次选出每个节点列表中的元素(这里也是list),进行俩俩组合，组合规则为：1. 首尾一致才凭借，比如[b,a]可以和[a,c]拼接为[b,a,c]，但[b,c]不可以与[a,b]拼接，2. 如果拼接后的三元组的首个标识和最后一个标识一样，需要过滤掉，比如[b,a]与[a,b]拼接后得到[b,a,b]，这种需要过滤掉，最后得到图3的结果  \n",
    "3）最后统计三角形个数，对于每个节点，如果同时出现了形如[a,b,c]和[a,c,b]这样的三元组，说明该节点处于三角形(a,b,c)中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkConf = org.apache.spark.SparkConf@9766443\n",
       "sc = org.apache.spark.SparkContext@2ad4a277\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@2ad4a277"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.graphx._\n",
    "val sparkConf: SparkConf = new SparkConf().setMaster(\"local[2]\")\n",
    "val sc: SparkContext = new SparkContext(sparkConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g = org.apache.spark.graphx.impl.GraphImpl@58ae0757\n",
       "newEdges = MapPartitionsRDD[24] at flatMap at <console>:32\n",
       "initGraph = org.apache.spark.graphx.impl.GraphImpl@3caaf92e\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@3caaf92e"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val g=util.GraphGenerators.rmatGraph(sc,32,64).removeSelfEdges()\n",
    "val newEdges=g.edges.flatMap((edge)=>Array(Edge(edge.srcId,edge.dstId,edge.attr),Edge(edge.dstId,edge.srcId,edge.attr)))\n",
    "val initGraph=Graph(g.vertices,newEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "secRDD = VertexRDDImpl[43] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VertexRDDImpl[43] at RDD at VertexRDD.scala:57"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//第一次aggregateMessage\n",
    "val secRDD=initGraph.aggregateMessages[Array[VertexId]](\n",
    "    sendMsg=(edge)=>edge.sendToDst(Array(edge.srcId)),\n",
    "    mergeMsg=(a,b)=>a++b //列表拼接用俩++\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((16,Array(18, 20, 21, 22, 24, 28, 17, 20)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secRDD.take(1)  //这里为(a,[b,c,d])的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "secVerticesRDD = MapPartitionsRDD[44] at map at <console>:32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[44] at map at <console>:32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//将(a,[b,c,d])的形式转换为[(a,b),(a,c),(a,d)]的格式\n",
    "val secVerticesRDD=secRDD.map(x=>{\n",
    "    val vi=x._1\n",
    "    val vil=x._2\n",
    "    var combineArray=Array[Tuple2[VertexId,VertexId]]()\n",
    "    for(nvi<-vil){\n",
    "        if(vi!=nvi && !combineArray.contains((vi,nvi))) combineArray=combineArray:+(vi,nvi)\n",
    "    }\n",
    "    (vi,combineArray)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((16,Array((16,18), (16,20), (16,21), (16,22), (16,24), (16,28), (16,17))))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secVerticesRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "secGraph = org.apache.spark.graphx.impl.GraphImpl@4724942b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@4724942b"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val secGraph=Graph(secVerticesRDD,initGraph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thrRDD = VertexRDDImpl[64] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VertexRDDImpl[64] at RDD at VertexRDD.scala:57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//第二次aggregateMessages\n",
    "val thrRDD=secGraph.aggregateMessages[Array[Tuple2[VertexId,VertexId]]](\n",
    "    sendMsg=(edge)=>edge.sendToDst(edge.srcAttr),\n",
    "    mergeMsg=(a,b)=>a++b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((16,Array((18,16), (18,19), (18,20), (18,24), (18,17), (18,26), (20,16), (20,18), (20,22), (20,24), (20,30), (20,17), (20,19), (20,21), (20,23), (21,16), (21,17), (21,20), (21,23), (22,16), (22,20), (22,26), (22,31), (22,30), (24,16), (24,17), (24,18), (24,20), (24,25), (24,26), (24,27), (24,28), (24,29), (28,16), (28,29), (28,24), (17,24), (17,25), (17,16), (17,18), (17,19), (17,20), (17,21), (20,16), (20,18), (20,22), (20,24), (20,30), (20,17), (20,19), (20,21), (20,23))))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expandRDD = MapPartitionsRDD[68] at map at <console>:43\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expand: (org: Array[(org.apache.spark.graphx.VertexId, org.apache.spark.graphx.VertexId)], tgt: Array[(org.apache.spark.graphx.VertexId, org.apache.spark.graphx.VertexId)])Array[(org.apache.spark.graphx.VertexId, org.apache.spark.graphx.VertexId, org.apache.spark.graphx.VertexId)]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[68] at map at <console>:43"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//将[a,b][b,c]拼接为[a,b,c]\n",
    "def expand(org:Array[Tuple2[VertexId,VertexId]],tgt:Array[Tuple2[VertexId,VertexId]]):Array[Tuple3[VertexId,VertexId,VertexId]]={\n",
    "    var combineArray=Array[Tuple3[VertexId,VertexId,VertexId]]()\n",
    "    for(i<-org){\n",
    "        for(j<-tgt){\n",
    "            if(i._2==j._1 && i._1!=j._2 && !combineArray.contains((i._1,i._2,j._2))) combineArray=combineArray:+(i._1,i._2,j._2)\n",
    "        }\n",
    "    }\n",
    "    combineArray\n",
    "}\n",
    "var expandRDD=secGraph.vertices.join(thrRDD).map(x=>(x._1,expand(x._2._1,x._2._2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((16,Array((16,18,19), (16,18,20), (16,18,24), (16,18,17), (16,18,26), (16,20,18), (16,20,22), (16,20,24), (16,20,30), (16,20,17), (16,20,19), (16,20,21), (16,20,23), (16,21,17), (16,21,20), (16,21,23), (16,22,20), (16,22,26), (16,22,31), (16,22,30), (16,24,17), (16,24,18), (16,24,20), (16,24,25), (16,24,26), (16,24,27), (16,24,28), (16,24,29), (16,28,29), (16,28,24), (16,17,24), (16,17,25), (16,17,18), (16,17,19), (16,17,20), (16,17,21))))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expandRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((16,10), (22,3), (28,2), (30,2), (24,12), (18,9), (20,13), (26,4), (19,4), (21,4), (25,3), (29,2), (27,1), (23,2), (17,12), (31,1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expandRDD.map(x=>{\n",
    "    //统计三角形数量\n",
    "    val vid=x._1\n",
    "    val arr=x._2\n",
    "    var cnt=0\n",
    "    for(i<-arr) if(arr.contains((i._1,i._3,i._2))) cnt=cnt+1\n",
    "    (vid,cnt/2)\n",
    "}).take(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((16,10), (22,3), (28,2), (30,2), (24,12), (18,9), (20,13), (26,4), (19,4), (21,4), (25,3), (29,2), (27,1), (23,2), (17,12), (31,1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//官方api结果\n",
    "initGraph.triangleCount().vertices.take(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark2.4.8 - Scala",
   "language": "scala",
   "name": "spark2.4.8_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
